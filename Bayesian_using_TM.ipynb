{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb42269e-99c2-49d3-abad-80f08b1b6ed1",
   "metadata": {},
   "source": [
    "# ***BNLEARN DATASET***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef699a-2dcc-4e41-9344-8e1bebb72946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bayesian dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "alarm_model = get_example_model(\"cancer\")\n",
    "samples = BayesianModelSampling(alarm_model).rejection_sample(size=20000)\n",
    "G = alarm_model\n",
    "samples.head()\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9536c-f892-4a98-8970-bbbf63bf5034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bayesian dataset\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.shell_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', font_weight='bold',\n",
    "        node_size=2000, font_size=12, arrowsize=20)\n",
    "plt.title(\"Causal Graph using PC Algorithm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39917b9a-5812-4df9-8c68-5d258f1fbd61",
   "metadata": {},
   "source": [
    "# ***DATA VISUALIZATION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974af9c-d6c3-40d6-9991-fad5de054686",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = samples.columns\n",
    "\n",
    "fig, axes = plt.subplots(1, len(columns), figsize=(50, 5), constrained_layout=True)\n",
    "\n",
    "for i, col in enumerate(columns):\n",
    "    ax = axes[i]\n",
    "    samples[col].value_counts().plot(kind='bar', ax=ax, color='skyblue', alpha=0.7)\n",
    "    ax.set_title(f\"Distribution of {col}\")\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb3d22f-c9ec-475c-bc0b-f2c8d82ddcec",
   "metadata": {},
   "source": [
    "# ***PREPROCESSING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c1ab2-4f15-4720-ba02-be9b44b22d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing underscores from G model nodes\n",
    "new_nodes = {node: node.replace('_', '') for node in G.nodes()}\n",
    "G = nx.relabel_nodes(G, new_nodes)\n",
    "\n",
    "print(\"Updated nodes:\", G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716e3bb-f9b8-4109-a346-b7a84c4e4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing underscores from Samples dataset nodes\n",
    "samples.columns = samples.columns.str.replace('_', '')\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a67eea-3778-4f8f-9bb6-6d1ea9ce0be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size\n",
    "size_sample = samples.sample(n=20000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed36db2-3eff-49c0-89b7-8eec7711e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "label_encoded_samples = size_sample.copy()\n",
    "for column in label_encoded_samples.columns:\n",
    "    if label_encoded_samples[column].dtype == 'object':\n",
    "        label_encoded_samples[column] = le.fit_transform(label_encoded_samples[column])\n",
    "\n",
    "label_encoded_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411fc454-0bae-48eb-a910-514cea3f04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded_samples.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629da17-ade1-4778-a407-0b5a32c07330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values in each column\n",
    "max_values = label_encoded_samples.max()+1\n",
    "max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace8718-e0f9-421d-8271-3d3360d7d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the entire dataset and calculate the overall max\n",
    "overall_max = label_encoded_samples.values.flatten().max()\n",
    "print(overall_max+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f7f75-875f-4b47-a2ea-6fea6803753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of variables have single value\n",
    "unique_counts = label_encoded_samples.nunique()\n",
    "\n",
    "single_unique_value_columns = unique_counts[unique_counts == 1]\n",
    "\n",
    "\n",
    "count_single_unique_value_columns = single_unique_value_columns.count()\n",
    "\n",
    "print(f'Number of columns with a single unique value: {count_single_unique_value_columns}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f04c6-b17e-4349-985e-a16ec89a7dfe",
   "metadata": {},
   "source": [
    "# **PC algoritm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bab6cd-fd35-42ca-a9fa-093a1a770b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pgmpy.estimators import PC\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "pc = PC(size_sample)\n",
    "model = pc.estimate(variant='orig',return_type='dag', significance_level=0.01,ci_test='chi_square')\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time_1 = end_time - start_time\n",
    "print(\"Time :\",execution_time_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb0177-aa60-4ded-9641-67cf0d6c236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_difference_2 = abs(len(G.nodes) - len(model.nodes))\n",
    "\n",
    "# because we are not considering directions\n",
    "ground_truth_edges = {tuple(sorted(edge)) for edge in G.edges()}\n",
    "inferred_edges = {tuple(sorted(edge)) for edge in model.edges()}\n",
    "\n",
    "false_positives = len(inferred_edges - ground_truth_edges)\n",
    "false_negatives = len(ground_truth_edges - inferred_edges)\n",
    "structural_hamming_distance_2 = false_positives + false_negatives\n",
    "\n",
    "\n",
    "missing_edges_count_2 = 0\n",
    "wrong_edges_count_2 = 0\n",
    "wrong_directed_edges_count_2 = 0\n",
    "\n",
    "for edge in ground_truth_edges:\n",
    "    if edge not in inferred_edges:\n",
    "        missing_edges_count_2 += 1\n",
    "\n",
    "for edge in inferred_edges:\n",
    "    if edge not in ground_truth_edges:\n",
    "        wrong_edges_count_2 += 1\n",
    "        \n",
    "print(\"Time :\",execution_time_1)\n",
    "print(\"nodes difference\", nodes_difference_2)\n",
    "print(\"Number of missing edges:\", missing_edges_count_2)\n",
    "print(\"Number of wrong edges:\", wrong_edges_count_2)\n",
    "print(\"Structural Hamming Distance:\", structural_hamming_distance_2)\n",
    "\n",
    "# True positives are the edges that are both in ground truth and inferred edges\n",
    "true_positives = len(ground_truth_edges & inferred_edges)\n",
    "\n",
    "# Precision \n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "\n",
    "# Recall \n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# F1 Score \n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Accuracy\n",
    "accuracy = true_positives / (true_positives + false_positives + false_negatives) if (true_positives + false_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Printing the metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db2c22-5569-4993-8564-b58a9aa3bf2b",
   "metadata": {},
   "source": [
    "# ***TSETLIN MACHINE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173eb92-20e8-4165-89e9-dba9d45b3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot-encoding\n",
    "one_encoded_samples = pd.get_dummies(size_sample).astype(int)\n",
    "one_encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8691cfa-26af-4fe1-bc62-faa8fe3c50e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiclass\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tmu.models.classification.vanilla_classifier import TMClassifier\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "one_hot_columns = one_encoded_samples.columns.tolist()\n",
    "label_columns = label_encoded_samples.columns.tolist()\n",
    "output_arrays = []\n",
    "output_arrays_1 = []\n",
    "start_time = time.time()\n",
    "\n",
    "for target_column in label_columns:\n",
    "    related_columns = [col for col in one_hot_columns if target_column.lower() in col.lower()]\n",
    "\n",
    "    X = one_encoded_samples.drop(columns=related_columns)\n",
    "    y = label_encoded_samples[target_column]\n",
    "\n",
    "    samples = pd.concat([X, y], axis=1)\n",
    "\n",
    "    class_counts = samples[target_column].value_counts()\n",
    "\n",
    "    majority_class_size = class_counts.max()\n",
    "\n",
    "    resampled_samples = []\n",
    "    for class_value, count in class_counts.items():\n",
    "        class_samples = samples[samples[target_column] == class_value]\n",
    "        \n",
    "        if count < majority_class_size:\n",
    "            class_samples_upsampled = resample(class_samples,\n",
    "                                               replace=True,  \n",
    "                                               n_samples=majority_class_size,  \n",
    "                                               random_state=42)\n",
    "            resampled_samples.append(class_samples_upsampled)\n",
    "        else:\n",
    "            resampled_samples.append(class_samples)\n",
    "\n",
    "    balanced_samples = pd.concat(resampled_samples)\n",
    "    balanced_samples = balanced_samples.sample(n=len(size_sample), random_state=1)\n",
    "\n",
    "\n",
    "    X_balanced = balanced_samples.drop(columns=[target_column])\n",
    "    y_balanced = balanced_samples[target_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = X_train.astype(np.uint32)\n",
    "    y_train = y_train.astype(np.uint32)\n",
    "    \n",
    "    \n",
    "    tm = TMClassifier(\n",
    "        number_of_clauses=2,  \n",
    "        T=10, # Threshold\n",
    "        s=1, # specificaity\n",
    "        platform=\"CPU\",\n",
    "        weighted_clauses=True,\n",
    "    )\n",
    "\n",
    "    learned_clauses_all_epochs = []  \n",
    "\n",
    "    for epoch in range(2):\n",
    "        tm.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "        \n",
    "            # as per the number of clauses used\n",
    "            for i in range(2):\n",
    "            # as per unique values in each column\n",
    "                for j in range(2):\n",
    "                        learned_clauses = tm.clause_banks[j].get_literals()[i][:len(X.columns) * 2] \n",
    "                        relevant_features = [feature for feature, clause in zip(X.columns.tolist() * 2, learned_clauses) if clause != 0]\n",
    "                        output_variable = target_column\n",
    "                        output_arrays.append([*relevant_features, output_variable])\n",
    "\n",
    "                        weights_of_learned_clauses = tm.weight_banks[j].get_weights()[i] \n",
    "                        output_arrays_1.append([*relevant_features, output_variable, weights_of_learned_clauses])    \n",
    "            \n",
    "        result = 100 * (tm.predict(X_test.to_numpy()) == y_test.to_numpy()).mean()\n",
    "\n",
    "        print(f\"Target Column: {target_column}\")\n",
    "        print(f\"Accuracy: {result:.2f}%\\n\")\n",
    "\n",
    "end_time = time.time()\n",
    "time_1 = end_time - start_time\n",
    "print(f\"Total execution time: {time_1} seconds\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db6980-c76b-4654-a31d-4ff88ade695e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the last element in every list before wight number is the output variable and remaining are literals for that specific clause\n",
    "output_arrays_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe0dfd-ac17-4bfb-aab1-e4c3da217b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove Suffix and Duplicates from lists (i.e clauses)\n",
    "start_time = time.time()\n",
    "def clean_and_deduplicate(arr):\n",
    "    cleaned = []\n",
    "    for item in arr:\n",
    "        cleaned.append(item.split('_')[0])  \n",
    "    \n",
    "    cleaned = list(set(cleaned))\n",
    "    return cleaned\n",
    "\n",
    "cleaned_output = [clean_and_deduplicate(sublist[:-2]) + [sublist[-2], abs(sublist[-1])] for sublist in output_arrays_1]\n",
    "\n",
    "print(cleaned_output)\n",
    "\n",
    "end_time = time.time()\n",
    "time_2 = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e342a-0c82-455f-8b8d-b7318c246a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Top variables are for each output element\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def calculate_input_output_frequency_weightage(cleaned_output, top_n):\n",
    "    output_data = defaultdict(lambda: defaultdict(lambda: {\"frequency\": 0, \"total_weightage\": 0}))\n",
    "    \n",
    "    for entry in cleaned_output:\n",
    "        *inputs, output, weight = entry\n",
    "        \n",
    "        for input_element in inputs:\n",
    "            output_data[output][input_element][\"frequency\"] += 1\n",
    "            output_data[output][input_element][\"total_weightage\"] += weight\n",
    "    \n",
    "    #print(\"Frequency and Weightage for each Input-Output Pair:\")\n",
    "    for output, input_data in output_data.items():\n",
    "        for input_element, values in input_data.items():\n",
    "            frequency = values[\"frequency\"]\n",
    "            total_weightage = values[\"total_weightage\"]\n",
    "            #print(f\"Output: {output}, Input: {input_element}, Frequency: {frequency}, Total Weightage: {total_weightage} = {frequency + total_weightage}\")\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for output, input_data in output_data.items():\n",
    "        sorted_inputs = sorted(input_data.items(), key=lambda x: x[1][\"frequency\"] * x[1][\"total_weightage\"], reverse=True)\n",
    "        \n",
    "        top_inputs = sorted_inputs[:top_n]\n",
    "\n",
    "        result.append([input for input, _ in top_inputs] + [output])\n",
    "\n",
    "    return result\n",
    "\n",
    "top_n = 5\n",
    "output = calculate_input_output_frequency_weightage(cleaned_output, top_n)\n",
    "print(\"\\nTop N Input-Output List:\")\n",
    "print(output)\n",
    "unique_array = output\n",
    "\n",
    "end_time = time.time()\n",
    "time_3 = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bafd57-c6cf-4f04-881f-fc0318ea43d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "result = {}\n",
    "\n",
    "for arr in unique_array:\n",
    "    output_element = arr[-1]  \n",
    "    input_elements = arr[:-1]  \n",
    "\n",
    "    \n",
    "    for input_element in input_elements:\n",
    "        \n",
    "        pair = (output_element, input_element)\n",
    "        reverse_pair = (input_element, output_element)  \n",
    "        \n",
    "        \n",
    "        if reverse_pair in result:\n",
    "            continue\n",
    "        \n",
    "        remaining_elements = [el for el in arr if el != input_element and el != output_element]\n",
    "        \n",
    "        \n",
    "        for next_arr in unique_array:\n",
    "            if next_arr[-1] == input_element:\n",
    "                \n",
    "                next_remaining_elements = [el for el in next_arr if el != input_element and el != next_arr[-1]]\n",
    "\n",
    "                \n",
    "                combined_remaining_elements = set(remaining_elements + next_remaining_elements)\n",
    "                combined_remaining_elements.discard(output_element)  \n",
    "                combined_remaining_elements.discard(input_element)  \n",
    "\n",
    "                result[pair] = list(combined_remaining_elements)\n",
    "\n",
    "for key, value in result.items():\n",
    "    print(f\"Pair: {key}, Remaining elements: {value}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "time_4 = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f082b-e5ed-48d2-a7f9-a7f1cd9311bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# whole testing\n",
    "import matplotlib.pyplot as plt\n",
    "from pgmpy.estimators import CITests\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "start_time = time.time()\n",
    "K = nx.Graph()\n",
    "separating_sets = {}\n",
    "\n",
    "for pair, Z in result.items():\n",
    "    X, Y = pair\n",
    "    \n",
    "    chi_square_test = CITests.chi_square(X=X, Y=Y, Z=[], data=label_encoded_samples, boolean=True, significance_level=0.05)\n",
    "    \n",
    "    if not chi_square_test:  \n",
    "        print(f\"{X} and {Y} are not independent. Testing conditional independence with Z={Z}.\")\n",
    "        \n",
    "        if Z:\n",
    "            independent = False  \n",
    "            for r in range(1, len(Z) + 1):  \n",
    "                for z_combination in itertools.combinations(Z, r):\n",
    "                    chi_square_test_with_Z = CITests.chi_square(X=X, Y=Y, Z=list(z_combination), data=label_encoded_samples, boolean=True, significance_level=0.05)\n",
    "                    \n",
    "                    if chi_square_test_with_Z:  \n",
    "                        print(f\"{X} and {Y} are conditionally independent with Z={z_combination}. No edge added.\")\n",
    "                        independent = True\n",
    "                        break\n",
    "            if not independent:\n",
    "                    print(f\"{X} and {Y} are not conditionally independent with Z={Z}. Adding edge to graph.\")\n",
    "                    K.add_edge(X, Y)\n",
    "            else:\n",
    "                    print(f\"{X} and {Y} are conditionally independent with Z={Z}. No edge added.\")\n",
    "    else:\n",
    "        print(f\"{X} and {Y} are independent. No edge added.\")\n",
    "        for z_element in Z:\n",
    "            chi_square_test_with_z_element = CITests.chi_square(X=X, Y=Y, Z=[z_element], data=label_encoded_samples, boolean=True, significance_level=0.05)\n",
    "        \n",
    "            if not chi_square_test_with_z_element:  \n",
    "                print(f\"{X} and {Y} become dependent given Z={z_element}. Adding edges.\")\n",
    "                if (X, Y) not in separating_sets:\n",
    "                    separating_sets[(X, Y)] = set()\n",
    "                separating_sets[(X, Y)].add(z_element)\n",
    "            else:\n",
    "                print(f\"{X} and {Y} remain independent given Z={z_element}. No edge added.\")\n",
    "        \n",
    "        \n",
    "\n",
    "pos = nx.shell_layout(K)  \n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(K, pos, with_labels=True, node_color='lightblue', node_size=3000, font_size=15, font_weight='bold', arrowsize=20)\n",
    "plt.title('Dependency Graph')\n",
    "plt.show()\n",
    "\n",
    "end_time = time.time()\n",
    "time_5 = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732838b-b798-4f17-9078-2781dbf3910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_difference_1 = abs(len(G.nodes) - len(K.nodes))\n",
    "\n",
    "ground_truth_edges = {tuple(sorted(edge)) for edge in G.edges()}\n",
    "inferred_edges = {tuple(sorted(edge)) for edge in K.edges()}\n",
    "\n",
    "false_positives = len(inferred_edges - ground_truth_edges)\n",
    "false_negatives = len(ground_truth_edges - inferred_edges)\n",
    "structural_hamming_distance_1 = false_positives + false_negatives\n",
    "\n",
    "\n",
    "missing_edges_count_1 = 0\n",
    "wrong_edges_count_1 = 0\n",
    "wrong_directed_edges_count_1 = 0\n",
    "\n",
    "for edge in ground_truth_edges:\n",
    "    if edge not in inferred_edges:\n",
    "        missing_edges_count_1 += 1\n",
    "\n",
    "for edge in inferred_edges:\n",
    "    if edge not in ground_truth_edges:\n",
    "        wrong_edges_count_1 += 1\n",
    "        \n",
    "print(\"Time\", time_1+time_2+time_3+time_4+time_5)        \n",
    "print(\"Nodes difference\", nodes_difference_1)\n",
    "print(\"Number of missing edges:\", missing_edges_count_1)\n",
    "print(\"Number of wrong edges:\", wrong_edges_count_1)\n",
    "print(\"Structural Hamming Distance:\", structural_hamming_distance_1)\n",
    "\n",
    "true_positives = len(ground_truth_edges & inferred_edges)\n",
    "\n",
    "# Precision\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "\n",
    "# Recall\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Accuracy\n",
    "accuracy = true_positives / (true_positives + false_positives + false_negatives) if (true_positives + false_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Printing the metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f6720-ec64-4cb4-83c8-1520f00149c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"False positives (edges in K but not in G):\", inferred_edges - ground_truth_edges)\n",
    "print(\"False negatives (edges in G but not in K):\", ground_truth_edges - inferred_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a620b-f452-428c-87a8-ecee4b981b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_difference_2 = (G.nodes) - (K.nodes)\n",
    "nodes_difference_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a0026-4098-4519-9b2e-8b09647387e2",
   "metadata": {},
   "source": [
    "# CHECK TEST PROVIDE WRONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d24fdd6-e7f3-4eb3-8423-d6c841fb88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we check the edges (i.e G but not in K), if found we find sepset for that edges if present means we did the tset but chi test provide they are independent \n",
    "ALL_EDGES =   ground_truth_edges - inferred_edges\n",
    "ALL_EDGES\n",
    "\n",
    "count = 0  \n",
    "\n",
    "for key_to_find in ALL_EDGES:\n",
    "    \n",
    "    if key_to_find in result or (key_to_find[1], key_to_find[0]) in result:\n",
    "        value = result.get(key_to_find, result.get((key_to_find[1], key_to_find[0])))\n",
    "        print(f\"Value associated with {key_to_find} or its reverse: {value}\")\n",
    "        count += 1  # Increase the count if the edge or its reverse is found\n",
    "    #else:\n",
    "        #print(f\"Neither key found in the dictionary: {key_to_find}\")\n",
    "\n",
    "# Print the final count\n",
    "print(f\"Total count of found edges: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a1032-d7ff-4bb8-8acf-a9eda3b11e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we check the edges (i.e K but not in G), if found we find sepset for that edges if found sepset == required sepset, then test provide wrong.\n",
    "ALL_EDGES =   inferred_edges - ground_truth_edges\n",
    "\n",
    "# Initialize a counter for matches\n",
    "match_count = 0\n",
    "\n",
    "# Iterate over ALL_EDGES and check for matches\n",
    "for key_to_find in ALL_EDGES:\n",
    "    if key_to_find in result or (key_to_find[1], key_to_find[0]) in result:\n",
    "        # Get value from result dictionary (either direct or reversed key)\n",
    "        value = result.get(key_to_find, result.get((key_to_find[1], key_to_find[0])))\n",
    "        print(f\"Value associated with {key_to_find} or its reverse: {value}\")\n",
    "        \n",
    "        # Get the minimal d-separating set for the edge\n",
    "        start, end = key_to_find\n",
    "        min_d_separator = G.minimal_dseparator(start=start, end=end)\n",
    "        print(f\"The minimal d-separating set between {start} and {end} is: {min_d_separator}\")\n",
    "        \n",
    "        # Ensure both are sets for comparison\n",
    "        min_d_separator_set = set(min_d_separator)\n",
    "        value_set = set(value)\n",
    "        \n",
    "        # Check if min_d_separator is a subset of value_set (with the extra elements allowed in value)\n",
    "        if min_d_separator_set.issubset(value_set):\n",
    "            print(f\"Match found for {key_to_find}: {min_d_separator_set} is a subset of {value_set}\")\n",
    "            # Increment the match count\n",
    "            match_count += 1\n",
    "        else:\n",
    "            print(f\"No match for {key_to_find}: {min_d_separator_set} is not a subset of {value_set}\")\n",
    "    else:\n",
    "        print(f\"Neither key found in the dictionary: {key_to_find}\")\n",
    "\n",
    "# Print the total match count\n",
    "print(f\"\\nTotal matches: {match_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405afd2-899a-420c-9450-0cfa04965ca4",
   "metadata": {},
   "source": [
    "# DIRECTED EDGES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b25611-cd9c-4596-9e58-ba0e33402366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colliders found\n",
    "skeleton = set(K.edges())\n",
    "\n",
    "\n",
    "directed_graph = set()\n",
    "\n",
    "skeleton_1 = set(skeleton)\n",
    "\n",
    "for (node1, node2), sep_set in separating_sets.items():\n",
    "    for sep_node in sep_set:\n",
    "        \n",
    "        if (sep_node, node1) in skeleton or (node1, sep_node) in skeleton:\n",
    "            directed_graph.add((node1, sep_node))  \n",
    "            skeleton_1.discard((sep_node, node1))\n",
    "            skeleton_1.discard((node1, sep_node))\n",
    "        \n",
    "        if (sep_node, node2) in skeleton or (node2, sep_node) in skeleton:\n",
    "            directed_graph.add((node2, sep_node))  \n",
    "            skeleton_1.discard((sep_node, node2))\n",
    "            skeleton_1.discard((node2, sep_node))\n",
    "\n",
    "print(\"Directed Graph:\", directed_graph)\n",
    "print(\"Remaining Skeleton_1:\", skeleton_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a4995-03b9-461e-8aaf-e23b473780c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in directed_graph:\n",
    "    skeleton_1.discard(edge)\n",
    "    skeleton_1.discard((edge[1], edge[0]))\n",
    "\n",
    "queue = list(directed_graph) \n",
    "\n",
    "while queue:\n",
    "    node1, node2 = queue.pop(0)  \n",
    "    last_element = node2  \n",
    "    \n",
    "    to_remove = []\n",
    "    for edge in skeleton_1:\n",
    "        if last_element in edge:\n",
    "            \n",
    "            new_edge = (last_element, edge[0]) if edge[1] == last_element else (last_element, edge[1])\n",
    "            directed_graph.add(new_edge)\n",
    "            queue.append(new_edge)  \n",
    "            to_remove.append(edge)\n",
    "    \n",
    "    for edge in to_remove:\n",
    "        skeleton_1.discard(edge)\n",
    "        \n",
    "for edge in skeleton_1:\n",
    "    directed_graph.add(edge)\n",
    "print(\"Directed Graph:\", directed_graph)\n",
    "print(\"Remaining Skeleton_1:\", skeleton_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0c986-bcda-468e-8973-fa21c1df7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "directed_graph = nx.DiGraph(directed_graph)\n",
    "\n",
    "# Define the position layout (shell layout in this case)\n",
    "pos = nx.shell_layout(G)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(directed_graph, pos, with_labels=True, node_color='lightblue', node_size=3000, font_size=15, font_weight='bold', arrowsize=20)\n",
    "plt.title('Dependency Graph')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5697a4-6140-4233-8ebd-43301058faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_difference_3 = abs(len(G.nodes) - len(directed_graph.nodes))\n",
    "print(\"nodes difference\", nodes_difference_3)\n",
    "\n",
    "ground_truth_edges = set(G.edges())\n",
    "inferred_edges = set(directed_graph.edges())\n",
    "\n",
    "false_positives = len(inferred_edges - ground_truth_edges)\n",
    "false_negatives = len(ground_truth_edges - inferred_edges)\n",
    "structural_hamming_distance_3 = false_positives + false_negatives\n",
    "\n",
    "print(\"Structural Hamming Distance:\", structural_hamming_distance_3)\n",
    "\n",
    "missing_edges_count_3 = 0\n",
    "wrong_edges_count_3 = 0\n",
    "wrong_directed_edges_count_3 = 0\n",
    "\n",
    "\n",
    "for edge in ground_truth_edges:\n",
    "    if edge not in inferred_edges and (edge[1], edge[0]) not in inferred_edges:\n",
    "        missing_edges_count_3 += 1\n",
    "\n",
    "\n",
    "for edge in inferred_edges:\n",
    "    if edge not in ground_truth_edges and (edge[1], edge[0]) not in ground_truth_edges:\n",
    "        wrong_edges_count_3 += 1\n",
    "    elif edge not in ground_truth_edges and (edge[1], edge[0]) in ground_truth_edges:\n",
    "        wrong_directed_edges_count_3 += 1\n",
    "\n",
    "\n",
    "print(\"Number of missing edges:\", missing_edges_count_3)\n",
    "print(\"Number of wrong edges:\", wrong_edges_count_3)\n",
    "\n",
    "\n",
    "print(\"Number of wrong direction edges:\", wrong_directed_edges_count_3)\n",
    "\n",
    "true_positives = len(ground_truth_edges & inferred_edges)\n",
    "\n",
    "# Precision\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "\n",
    "# Recall\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Accuracy\n",
    "accuracy = true_positives / (true_positives + false_positives + false_negatives) if (true_positives + false_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Printing the metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
