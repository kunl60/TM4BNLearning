# TM4BNLearning
The PC (Peter-Clark) algorithm is a widely used method in causal inference to learn the structure of Bayesian networks. Despite its popularity, the PC algorithm suffers from significant time complexity, particularly as the size of the data set increases, which limits its practical application in large-scale real-world problems. In this study, we propose a novel approach that utilizes the Tsetlin Machine (TM) to construct Bayesian structures more efficiently. Our method utilizes the most important literals extracted from the TM and performs conditional independence tests (CI) on these selected literals instead of the full set of variables, leading to a significant reduction in computational time. We implemented our approach and compared it to the PC-Stable (PCS) and original PC algorithms (PCO). Our evaluation includes datasets from the pgmpy repository, such as MUNIN, HEPAR2, etc. Our findings show that our TM-based method not only reduces computational complexity but also maintains competitive accuracy in causal discovery, making it a viable alternative to traditional PC algorithm implementations, offering greater efficiency without sacrificing performance
